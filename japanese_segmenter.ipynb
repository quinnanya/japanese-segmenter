{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Japanese text segmenter\n",
    "\n",
    "version 1.0\n",
    "\n",
    "For Japanese text to be usable for various language-agnostic digital humanities tools and methodologies (e.g. word counts, topic modeling, or word vectors), it needs to be *segmented* -- i.e. spaces need to be artificially inserted.\n",
    "\n",
    "[MeCab](https://taku910.github.io/mecab/) is widely used as a tool for Japanese segmentation and part-of-speech tagging, but if you run into problems intalling or using MeCab, you can try this Jupyter notebook, which uses [RakutenMA Python](https://github.com/ikegami-yukino/rakutenma-python) as its segmenter. If you want to try out RakutenMA to see how well it works for your text before using the notebook, you can [use the web-based interface for RakutenMA here](http://rakuten-nlp.github.io/rakutenma/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested citation\n",
    "If you use this notebook as part of your project workflow, you can cite it with something to the effect of:\n",
    "\n",
    "Dombrowski, Quinn. *Japanese text segmenter* Jupyter notebook. https://github.com/quinnanya/japanese-segmenter. 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preparation\n",
    "This notebook has two versions of the segmenter code: one that converts a single file, and one that converts everything in a folder.\n",
    "\n",
    "Before using this notebook, you should make sure your texts are saved as .txt files with UTF-8 encoding (**not** shift-JIS, which many Japanese websites use).\n",
    "\n",
    "If you're not sure whether your text file uses UTF-8 encoding, you can open it with the free cross-platform [Atom](https://atom.io/) text editor. In the bottom right corner, it will show your file encoding. If you save the text file in Atom, it will convert it to UTF-8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install segmenter module\n",
    "The Japanese segmenter Python module isn't installed automatically with Anaconda (if you're using that to run Jupyter notebooks). It also isn't available through conda. Instead, the code block below installs it in your Anaconda directory so the notebook can use it.\n",
    "\n",
    "You only have to run the code block below the first time you use this notebook. If you run it again, you'll just get a message saying \"Requirement already satisfied\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rakutenma in /Users/qad/anaconda3/lib/python3.6/site-packages (0.3.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rakutenma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "The code block below imports a few modules that are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os is used for things like changing directories and listing files\n",
    "import os\n",
    "\n",
    "# io is used for opening and writing files\n",
    "import io\n",
    "\n",
    "#itertools is used for some of the iterative code\n",
    "#from itertools import chain\n",
    "\n",
    "# glob is used to find all the pathnames matching a specified pattern \n",
    "#( here, all text files)\n",
    "import glob\n",
    "\n",
    "# rakutenma is the Japanese segmenter\n",
    "from rakutenma import RakutenMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the source directory\n",
    "Within the single quotes, put the full path to the folder that contains the .txt file or file(s) you want to segment. If you want to segment multiple files, it's easiest if you put them in a folder that only contains those files. If you want to segment just one single file, you can put it anywhere as long as you can get the full path to that directory.\n",
    "\n",
    "For instance, the default path to the Documents directory is (substituting your user name on the computer for YOUR-USER-NAME):\n",
    "\n",
    "- On Mac: '/Users/YOUR-USER-NAME/Documents'\n",
    "- On Windows: 'C:\\Users\\YOUR-USER-NAME\\Documents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the full path to the directory\n",
    "# where you have the plain text file(s)\n",
    "sourcefiledirectory = '/Users/qad/Documents/jpnlp'\n",
    "\n",
    "# Changing the directory to where you've stored the source texts,\n",
    "# so you can open them in later code blocks\n",
    "os.chdir(sourcefiledirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RakutenMA segmenter code & model\n",
    "The code block below loads the default model for Japanese and a required hash function used to map the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rma = RakutenMA(phi=1024, c=0.007812)  # Specify hyperparameter for SCW (for demonstration purpose)\n",
    "rma.load(\"model_ja.json\")\n",
    "rma.hash_func = rma.create_hash_func(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting a single file\n",
    "Use the code block below if you have one single file that you need to segment. Put the filename within the single quotes after *filename*, replacing *泉鏡花_海異記.txt*.\n",
    "\n",
    "Make sure that you've indicated the path to the directory where the file is located for *sourcefiledirectory* in the code block above, and run that code block first.\n",
    "\n",
    "This code block will create a new plain text file with *_segmented* appended to the end of the source filename.\n",
    "\n",
    "If you want to see the output within the Jupyter notebook, you can delete the # character before the word *print* in the last line before you run the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your input filename here\n",
    "filename = '泉鏡花_海異記.txt'\n",
    "# The name of the output file appends _segmented to the end of the source file\n",
    "outname = filename.replace('.txt', '_segmented.txt')\n",
    "# Open the input file\n",
    "f = open(filename, 'r')\n",
    "# Read the input file\n",
    "text = f.read()\n",
    "# Create and open the output file\n",
    "with open(outname, 'w') as out:\n",
    "# Use the rma.tokenize function from RakutenMA to create a list of segmented words\n",
    "    segmentedwords = (rma.tokenize(text))\n",
    "# For each word in the segmented words list...\n",
    "    for segmentedword in segmentedwords:\n",
    "# Grab just the segmented word, not the linguistic annotations that RakutenMA creates\n",
    "        word = segmentedword[0]\n",
    "# Write the word to the output file\n",
    "        out.write(word)\n",
    "# Put a space between each word\n",
    "        out.write(\" \")\n",
    "# Delete the # character below to also print out the words within the Jupyter notebook\n",
    "        #print(word, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting multiple files\n",
    "If you just need to segment a single .txt file, you don't need the following code block.\n",
    "\n",
    "If you want to segment multiple .txt files, make sure they're all in the directory that you specified at the top of this notebook -- and make sure there aren't other text files that you *don't* want segmented in the same directory.\n",
    "\n",
    "Running the code block below will generate an output file (with *segmented* appended to the filename) for each .txt file in the directory.\n",
    "\n",
    "If you want to have the output displayed in this Jupyter notebook as well, you can delete the # character before *print* in the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the source file directory you indicated in a code block above for files\n",
    "for filename in os.listdir(sourcefiledirectory):\n",
    "# If there are files that end in .txt...\n",
    "    if filename.endswith(\".txt\"):\n",
    "# But they don't end with _segmented.txt (i.e. previous output files)...\n",
    "        if not filename.endswith(\"_segmented.txt\"):\n",
    "#One at a time, open the .txt files and read the contents  \n",
    "            f = open(filename, 'r')\n",
    "            text = f.read()\n",
    "# The name of the output file appends _segmented to the end of the source file\n",
    "            outname = filename.replace('.txt', '_segmented.txt')\n",
    "# Create and open the output file\n",
    "            with open(outname, 'w') as out:\n",
    "# Use the rma.tokenize function from RakutenMA to create a list of segmented words\n",
    "                segmentedwords = (rma.tokenize(text))\n",
    "# For each word in the segmented words list...\n",
    "                for segmentedword in segmentedwords:\n",
    "# Grab just the segmented word, not the linguistic annotations that RakutenMA creates\n",
    "                    word = segmentedword[0]\n",
    "# Write the word to the output file\n",
    "                    out.write(word)\n",
    "# Put a space between each word\n",
    "                    out.write(\" \")\n",
    "# Delete the # character below to also print out the words within the Jupyter notebook\n",
    "                    #print(word, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
